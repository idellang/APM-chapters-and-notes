---
title: "Chap12 - Exercise"
author: "Me"
date: "10/3/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown
#1 
The hepatic injury dataset was described in the introductory chapter and contains 281 unique compounds, each of which has been classified cuasing no liver damage, mild damage, and severe damage. These compounds were analyzed with 184 biological screens to assess each compounds effect on particular biology relevant target in body. The larger the value of these predictors, the higher the activity of the compound. In addition to biological screens, 192 chemical fingerprints predictors were determined for these compounds. Each of these predictors represent a substructure (i.e atom or combination of atoms within compounds) and are either counts of number of substructures or an indicator of presence or absence of particular substructure. The objective of this dataset is to build predictive model for hepatic injury so that other compounds can be screened for likelihood of causing hepatic injury.
```{r}
library(caret)
library(AppliedPredictiveModeling)
data(hepatic)
bio
```

The matrices bio and chem contain biological assay and chemical fingerptrints for 281 compounds, while vector injury contains liver damage classification
a - given imbalance in hepatic injury status, how would you create training and testing set
b - which classification statistic would you choose
c - split the data, preprocess, build models for biological and chemical predictors. Which model has the best predictive ability, which predictor contain most information?
d - for optimal models, what are top 5 important factors
e - combine predictors into one predictor set, which model yield best performance? IS the model better than either model previously? What are top predictors
f - which model would you recommend?

```{r}
table(injury)
```
Lump all compounds into yes category
```{r}
library(forcats)
any_damage = fct_collapse(injury, 'Yes' = c('Mild','Severe'), No = 'None')
table(any_damage)
```
Here we verify that using createdata partition does not change proportion of yes and no from population proportion. This is important when one's problem has non equal class proportions
```{r}
k = createDataPartition(any_damage, p = .8, list = F, times = 1)
table(any_damage)/ sum(table(any_damage))

table(any_damage[t])/ sum(table(any_damage[t])) #proportion from resampling
```
Check again with k = 10
```{r}
k = createDataPartition( any_damage, p=0.8, list=FALSE, times=10 )
table(any_damage[k[,1]])/ sum(table(any_damage[k[,1]]))
```
Using biological predictors
```{r}
#remove near zero var
zv_cols = nearZeroVar(bio)
X = bio[,-zv_cols]

#find linearly dependent columns
findLinearCombos(X)
```

Build linaer model with this data

Logistic regression model
```{r}
ctrl = trainControl(summaryFunction = twoClassSummary, classProbs = T)
set.seed(100)
glm_model = train(X, any_damage, method = 'glm', metric = 'ROC', trControl = ctrl)
glm_preds = predict(glm_model, X, type = 'prob')
glm_roc_curve = pROC::roc(response = any_damage, predictor = glm_preds[,1])
glm_auc = glm_roc_curve$auc[1]
glm_results = list(classifier = glm_model, predictions = glm_preds, roc = glm_roc_curve, auc = glm_auc)
glm_results
```

#LDA
```{r}
set.seed(100)
lda_model = train(X, any_damage, method = 'lda', preProcess = c('center','scale'), metric = 'ROC', trControl = ctrl)
lda_preds = predict(lda_model, X, type = 'prob')
lda_roc_curve = pROC::roc(response = any_damage, predictor = lda_preds[,1])
lda_auc = lda_roc_curve$auc[1]
lda_results = list(classifier = lda_model, predictions = lda_preds, roc = lda_roc_curve, auc = lda_auc)
lda_results
```
#PLS

```{r}
set.seed(100)
pls_model = train(X, any_damage, method = 'pls', tuneGrid = expand.grid(.ncomp = 1:10), preProcess = c('center','scale'), metric = 'ROC', trControl = ctrl)
pls_preds = predict(pls_model, X, type = 'prob')
pls_roc_curve = pROC::roc(response = any_damage, predictor = pls_preds[,1])
pls_auc = pls_roc_curve$auc[1]
pls_results = list(classifier = pls_model, predictions = pls_preds, roc = pls_roc_curve, auc = pls_auc)
pls_results
```
#Penalized methods
```{r}
glm_grid = expand.grid(.alpha = c(0, .1, .2, .4, .6, .8, 1), 
                       .lambda = seq(0.01, .2, length = 20))

set.seed(100)
glmnet_model = train(X, any_damage, method = 'glmnet', 
                  tuneGrid = glm_grid, 
                  preProcess = c('center','scale'), metric = 'ROC', trControl = ctrl)

glmnet_preds = predict(glmnet_model, X, type = 'prob')
glmnet_roc_curve = pROC::roc(response = any_damage, predictor = glmnet_preds[,1])
glmnet_auc = glmnet_roc_curve$auc[1]
glmnet_results = list(classifier = glmnet_model, predictions = glmnet_preds, roc = glmnet_roc_curve, auc = glmnet_auc)
glmnet_results
```


#Nearest Shruken method1

```{r}
nsc_grid = expand.grid(.threshold = 0:25)

set.seed(100)
nsc_model = train(X, any_damage, method = 'pam', 
                  tuneGrid = nsc_grid, 
                  preProcess = c('center','scale'), metric = 'ROC', trControl = ctrl)

nsc_preds = predict(nsc_model, X, type = 'prob')
nsc_roc_curve = pROC::roc(response = any_damage, predictor = nsc_preds[,1])
nsc_auc = nsc_roc_curve$auc[1]
nsc_results = list(classifier = nsc_model, predictions = nsc_preds, roc = nsc_roc_curve, auc = nsc_auc)
nsc_results
```

```{r}
bio_result = list(glm = glm_results, lda = lda_results, glmnet = glmnet_results, nsc = nsc_results, pls = pls_results)

df = rbind( data.frame(name="LR", auc=bio_result$glm$auc), data.frame(name="LDA", auc=bio_result$lda$auc),
            data.frame(name="PLSDA", auc=bio_result$pls$auc), data.frame(name="GLMNET", auc=bio_result$glmnet$auc),
            data.frame(name="NSC", auc=bio_result$nsc$auc) )
df
```
Best model is linear model
```{r}
varImp(bio_result$glm$classifier)
```

# Chemical predictors
```{r}
zv_cols = nearZeroVar(chem)
X = chem[,-zv_cols]

flc = findLinearCombos(X)
X = X[,-flc$remove]
X
```

Build models

LM
```{r}
ctrl = trainControl(summaryFunction = twoClassSummary, classProbs = T)
set.seed(100)
glm_model = train(X, any_damage, method = 'glm', metric = 'ROC', trControl = ctrl)
glm_preds = predict(glm_model, X, type = 'prob')
glm_roc_curve = pROC::roc(response = any_damage, predictor = glm_preds[,1])
glm_auc = glm_roc_curve$auc[1]
glm_results = list(classifier = glm_model, predictions = glm_preds, roc = glm_roc_curve, auc = glm_auc)
glm_results
```
LDA
```{r}
set.seed(100)
lda_model = train(X, any_damage, method = 'lda', preProcess = c('center','scale'), metric = 'ROC', trControl = ctrl)
lda_preds = predict(lda_model, X, type = 'prob')
lda_roc_curve = pROC::roc(response = any_damage, predictor = lda_preds[,1])
lda_auc = lda_roc_curve$auc[1]
lda_results = list(classifier = lda_model, predictions = lda_preds, roc = lda_roc_curve, auc = lda_auc)
lda_results
```
PLSDA
```{r}
set.seed(100)
pls_model = train(X, any_damage, method = 'pls', tuneGrid = expand.grid(.ncomp = 1:10), preProcess = c('center','scale'), metric = 'ROC', trControl = ctrl)
pls_preds = predict(pls_model, X, type = 'prob')
pls_roc_curve = pROC::roc(response = any_damage, predictor = pls_preds[,1])
pls_auc = pls_roc_curve$auc[1]
pls_results = list(classifier = pls_model, predictions = pls_preds, roc = pls_roc_curve, auc = pls_auc)
pls_results
```
GLMNET
```{r}
glm_grid = expand.grid(.alpha = c(0, .1, .2, .4, .6, .8, 1), 
                       .lambda = seq(0.01, .2, length = 20))

set.seed(100)
glmnet_model = train(X, any_damage, method = 'glmnet', 
                  tuneGrid = glm_grid, 
                  preProcess = c('center','scale'), metric = 'ROC', trControl = ctrl)

glmnet_preds = predict(glmnet_model, X, type = 'prob')
glmnet_roc_curve = pROC::roc(response = any_damage, predictor = glmnet_preds[,1])
glmnet_auc = glmnet_roc_curve$auc[1]
glmnet_results = list(classifier = glmnet_model, predictions = glmnet_preds, roc = glmnet_roc_curve, auc = glmnet_auc)
glmnet_results
```

```{r}
nsc_grid = expand.grid(.threshold = 0:25)

set.seed(100)
nsc_model = train(X, any_damage, method = 'pam', 
                  tuneGrid = nsc_grid, 
                  preProcess = c('center','scale'), metric = 'ROC', trControl = ctrl)

nsc_preds = predict(nsc_model, X, type = 'prob')
nsc_roc_curve = pROC::roc(response = any_damage, predictor = nsc_preds[,1])
nsc_auc = nsc_roc_curve$auc[1]
nsc_results = list(classifier = nsc_model, predictions = nsc_preds, roc = nsc_roc_curve, auc = nsc_auc)
nsc_results
```

```{r}
chemical_result = list(glm = glm_results, lda = lda_results, glmnet = glmnet_results, nsc = nsc_results, pls = pls_results)

df = rbind( data.frame(name="LR", auc=chemical_result$glm$auc), data.frame(name="LDA", auc=chemical_result$lda$auc),
            data.frame(name="PLSDA", auc=chemical_result$pls$auc), data.frame(name="GLMNET", auc=chemical_result$glmnet$auc),
            data.frame(name="NSC", auc=chemical_result$nsc$auc) )
df
```
```{r}
varImp(chemical_result$glm$classifier)
```
Plot the two logistic regression ROC curves
```{r}
plot(bio_result$glm$roc, legacy.axes = T, add = F, col= 'gray')
plot(chemical_result$glm$roc, legacy.axes = T, add = T)
legend( 0.6, 0.2, c("LR (biological)","LR (chemical)"), col=c("gray","black"), lty=c(1,1) )
```

Use all predictors
```{r}
all_data = cbind(bio, chem)
zv_cols = nearZeroVar(all_data)

X = all_data[,-zv_cols]

flc= findLinearCombos(X)
X = X[, -flc$remove]
```

Build models

```{r}
#LM
ctrl = trainControl(summaryFunction = twoClassSummary, classProbs = T)
set.seed(100)
glm_model = train(X, any_damage, method = 'glm', metric = 'ROC', trControl = ctrl)
glm_preds = predict(glm_model, X, type = 'prob')
glm_roc_curve = pROC::roc(response = any_damage, predictor = glm_preds[,1])
glm_auc = glm_roc_curve$auc[1]
glm_results = list(classifier = glm_model, predictions = glm_preds, roc = glm_roc_curve, auc = glm_auc)

#LDA
lda_model = train(X, any_damage, method = 'lda', preProcess = c('center','scale'), metric = 'ROC', trControl = ctrl)
lda_preds = predict(lda_model, X, type = 'prob')
lda_roc_curve = pROC::roc(response = any_damage, predictor = lda_preds[,1])
lda_auc = lda_roc_curve$auc[1]
lda_results = list(classifier = lda_model, predictions = lda_preds, roc = lda_roc_curve, auc = lda_auc)

#PLS
pls_model = train(X, any_damage, method = 'pls', tuneGrid = expand.grid(.ncomp = 1:10), preProcess = c('center','scale'), metric = 'ROC', trControl = ctrl)
pls_preds = predict(pls_model, X, type = 'prob')
pls_roc_curve = pROC::roc(response = any_damage, predictor = pls_preds[,1])
pls_auc = pls_roc_curve$auc[1]
pls_results = list(classifier = pls_model, predictions = pls_preds, roc = pls_roc_curve, auc = pls_auc)

#GLMNET
glm_grid = expand.grid(.alpha = c(0, .1, .2, .4, .6, .8, 1), 
                       .lambda = seq(0.01, .2, length = 20))

glmnet_model = train(X, any_damage, method = 'glmnet', 
                  tuneGrid = glm_grid, 
                  preProcess = c('center','scale'), metric = 'ROC', trControl = ctrl)

glmnet_preds = predict(glmnet_model, X, type = 'prob')
glmnet_roc_curve = pROC::roc(response = any_damage, predictor = glmnet_preds[,1])
glmnet_auc = glmnet_roc_curve$auc[1]
glmnet_results = list(classifier = glmnet_model, predictions = glmnet_preds, roc = glmnet_roc_curve, auc = glmnet_auc)


#NSC
nsc_grid = expand.grid(.threshold = 0:25)

nsc_model = train(X, any_damage, method = 'pam', 
                  tuneGrid = nsc_grid, 
                  preProcess = c('center','scale'), metric = 'ROC', trControl = ctrl)

nsc_preds = predict(nsc_model, X, type = 'prob')
nsc_roc_curve = pROC::roc(response = any_damage, predictor = nsc_preds[,1])
nsc_auc = nsc_roc_curve$auc[1]
nsc_results = list(classifier = nsc_model, predictions = nsc_preds, roc = nsc_roc_curve, auc = nsc_auc)
```



```{r}
all_results  = list(glm = glm_results, lda = lda_results, glmnet = glmnet_results, nsc = nsc_results, pls = pls_results)

df = rbind( data.frame(name="LR", auc=all_results$glm$auc), data.frame(name="LDA", auc=all_results$lda$auc),
            data.frame(name="PLSDA", auc=all_results$pls$auc), data.frame(name="GLMNET", auc=all_results$glmnet$auc),
            data.frame(name="NSC", auc=all_results$nsc$auc) )
df
```

```{r}
varImp(chemical_result$glm$classifier)
```

```{r}
varImp(all_results$glm$classifier)
```

#2 
In exercise 4, we described a data set which contained 96 oil samples from one of seven types of oils. Gas cromatography was performed on each sample and percentage of each type of 7 fatty acids was determined. We would like to use these data to build model that predicts type of oil based on fatty acid percentages

a - These data suffer from extreme imbalance, should the data be split?
b - which classification statistic would you use?
c - which model performs best?
```{r}
library(caret)
library(AppliedPredictiveModeling)
library(pROC)
```
```{r}
data(oil)
table(oilType)
```
Preprocess data
```{r}
zv_cols = nearZeroVar(fattyAcids)
findLinearCombos(fattyAcids)
fattyAcids
```
Build models

Use probability of correct classification not area under the curve
```{r}
set.seed(100)
lda_model = train(fattyAcids, oilType, method = 'lda', preProcess = c('center','scale'))
y_hat = predict(lda_model, fattyAcids)
cm = confusionMatrix(data = y_hat, reference = oilType)
lda = list(classifier = lda_model, confusion_matrix = cm)
lda
```
#Penalized methods
```{r}
glmnet_grid = expand.grid(.alpha = c(0, .1 , .2, .4, .6, .8 , 1), 
                          .lambda=  seq(.01, .2, length = 20))
set.seed(100)
glmnet_model = train(fattyAcids, oilType, method = 'glmnet', tuneGrid = glmnet_grid,  preProcess = c('center','scale'))
y_hat = predict(glmnet_model, fattyAcids)
cm = confusionMatrix(data = y_hat, reference = oilType)
glm = list(classifier = glmnet_model, confusion_matrix = cm)

```

#NSC
```{r}
nsc_grid = expand.grid(.threshold=0:25)
set.seed(100)
nsc_model = train(fattyAcids, oilType, method = 'pam', tuneGrid = nsc_grid,  preProcess = c('center','scale'))
y_hat = predict(nsc_model, fattyAcids)
cm = confusionMatrix(data = y_hat, reference = oilType)
nsc = list(classifier = glmnet_model, confusion_matrix = cm)
```
```{r}
results = list(lda = lda, glm = glm, nsc = nsc)
```


```{r}
df = rbind(data.frame(name = 'LDA', Accuracy = results$lda$confusion_matrix$overall[1]), 
      data.frame(name = 'GLMNET', Accuracy = results$glm$confusion_matrix$overall[1]), 
      data.frame(name = 'NSC', Accuracy = results$nsc$confusion_matrix$overall[1]))
df
```



















